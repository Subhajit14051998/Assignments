{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. The python program to extract the video URL of the first five\n",
    "videos.\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "video_urls = \\[\\]\n",
    "\n",
    "for link in soup.find_all('a', {'class': 'yt-simple-endpoint style-scope\n",
    "ytd-grid-video-renderer'}):\n",
    "\n",
    "video_urls.append('https://www.youtube.com' + link\\['href'\\])\n",
    "\n",
    "first_five_video_urls = video_urls\\[:5\\]\n",
    "\n",
    "print(first_five_video_urls)\n",
    "\n",
    "2\\. The python program to extract the URL of the video thumbnails of the\n",
    "first five videos.\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "thumbnail_urls = \\[\\]\n",
    "\n",
    "for thumbnail in soup.find_all('img', {'class': 'style-scope\n",
    "yt-img-shadow'}):\n",
    "\n",
    "thumbnail_urls.append(thumbnail\\['src'\\])\n",
    "\n",
    "first_five_thumbnail_urls = thumbnail_urls\\[:5\\]\n",
    "\n",
    "print(first_five_thumbnail_urls)\n",
    "\n",
    "3\\. The python program to extract the title of the first five videos.\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "titles = \\[\\]\n",
    "\n",
    "for title in soup.find_all('a', {'id': 'video-title'}):\n",
    "\n",
    "titles.append(title.text.strip())\n",
    "\n",
    "first_five_titles = titles\\[:5\\]\n",
    "\n",
    "print(first_five_titles)\n",
    "\n",
    "4\\. The python program to extract the number of views of the first five\n",
    "videos.\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "views = \\[\\]\n",
    "\n",
    "for view in soup.find_all('span', {'class': 'style-scope\n",
    "ytd-grid-video-renderer'}):\n",
    "\n",
    "if 'views' in view.text:\n",
    "\n",
    "views.append(view.text.strip())\n",
    "\n",
    "first_five_views = views\\[:5\\]\n",
    "\n",
    "print(first_five_views)\n",
    "\n",
    "5\\. Program to extract the time of posting of the first five videos:\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "post_times = \\[\\]\n",
    "\n",
    "for time in soup.find_all('span', {'class': 'style-scope\n",
    "ytd-grid-video-renderer'}):\n",
    "\n",
    "if 'ago' in time.text:\n",
    "\n",
    "post_times.append(time.text.strip())\n",
    "\n",
    "first_five_post_times = post_times\\[:5\\]\n",
    "\n",
    "print(first_five_post_times)\n",
    "\n",
    "To save the scraped data into a CSV file, we can use the csv module in\n",
    "Python. Here's an example of how to do it:\n",
    "\n",
    "import csv\n",
    "\n",
    "\\# Assuming we have already extracted the required data\n",
    "\n",
    "\\# in the variables: first_five_video_urls, first_five_thumbnail_urls,\n",
    "\n",
    "\\# first_five_titles, first_five_views, and first_five_post_times.\n",
    "\n",
    "data = zip(first_five_video_urls, first_five_thumbnail_urls,\n",
    "first_five_titles, first_five_views, first_five_post_times)\n",
    "\n",
    "with open('youtube_data.csv', 'w', newline='', encoding='utf-8') as\n",
    "file:\n",
    "\n",
    "writer = csv.writer(file)\n",
    "\n",
    "writer.writerow(\\['Video URL', 'Thumbnail URL', 'Title', 'Views', 'Post\n",
    "Time'\\])\n",
    "\n",
    "writer.writerows(data)\n",
    "\n",
    "print('Data saved to youtube_data.csv')\n",
    "\n",
    "We can integrate these code snippets into our user interface and deploy\n",
    "it on AWS."
   ],
   "id": "9980e043-f65f-43dc-a094-d37a3159d597"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
